{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "from numpy.matlib import repmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Python/')\n",
    "from Preprocessing import standardize\n",
    "from Evaluation import split_train_test_ma, train_model, eval_model\n",
    "from Databases import get_databases_path, get_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "databases_path = '../../Databases/Sinteticas'\n",
    "paths = get_databases_path(databases_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the attributes and labels\n",
    "attr_df = get_database(paths[1], 'database_attr.csv')\n",
    "labels_df = get_database(paths[1], 'database_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the attributes\n",
    "standardized_attr_df = standardize(attr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = split_train_test_ma(standardized_attr_df, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = y_train.columns.size\n",
    "Ntr = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1./(1 + np.exp(-a))\n",
    "\n",
    "def training_LFCmodel(X, Y):\n",
    "    X.loc[:,'b'] = np.zeros((X.shape[0],1))\n",
    "    R = Y.shape[1] # Number of annotators.\n",
    "    D = X.shape[1] # Input space dimension\n",
    "    N = X.shape[0] # Number of samples.\n",
    "    \n",
    "    # Parameters initialization\n",
    "    loglik1 = 10000000\n",
    "    difloglik = 1\n",
    "    difloglik1 = -1\n",
    "    mui = np.array(Y.mean(axis=1)).reshape(Y.shape[0],1)\n",
    "\n",
    "    w = np.dot(inv(np.dot(X.T,X) + 1e-20*np.eye(D)), np.dot(X.T,mui))\n",
    "    i = 0\n",
    "    \n",
    "    while abs(difloglik) > 0.2 and i<100: \n",
    "        # M-step\n",
    "        # We initialize the optimization parameters w.\n",
    "        pi = sigmoid(np.dot(X,w))   \n",
    "        gr = np.dot(X.T, (mui - pi))\n",
    "\n",
    "        diag_aux = np.multiply(pi,(1-pi))\n",
    "        diag = diag_aux*np.identity(len(diag_aux))\n",
    "\n",
    "        H  = np.dot(np.dot(-X.T,diag),X)\n",
    "        w  = w - np.dot(inv(H + 1e-20*np.eye(D)),gr)\n",
    "\n",
    "        alpha = np.multiply(repmat(mui,1,R),Y).sum()/mui.sum()\n",
    "        beta =  np.multiply(repmat((1-mui),1,R),(1-Y)).sum()/(1-mui).sum()\n",
    "\n",
    "        # E-step\n",
    "        pi = sigmoid(np.dot(X,w))  \n",
    "        ai = np.multiply(np.power(repmat(alpha,N,1),Y),np.power(repmat((1-alpha),N,1),(1-Y)))\n",
    "        ai = np.array(np.prod(ai, axis=1)).reshape(ai.shape[0],1)\n",
    "\n",
    "        bi = np.multiply(np.power(repmat(beta,N,1),(1-Y)), np.power(repmat((1-beta),N,1),Y))\n",
    "        bi = np.array(np.prod(bi, axis=1)).reshape(ai.shape[0],1)\n",
    "\n",
    "        mui = np.multiply(ai, pi)/(np.multiply(ai,pi) + np.multiply(bi,(1 - pi)))\n",
    "\n",
    "        loglik2 = -(np.log(np.multiply(ai, pi) + np.multiply((1-pi),bi)).sum())\n",
    "        difloglik = abs(loglik2 - loglik1)\n",
    "        difloglik1 = (loglik2 - loglik1)\n",
    "        loglik1 = loglik2\n",
    "        print('Verosimilitud:', abs(difloglik))\n",
    "\n",
    "        i+=1    \n",
    "    return w, alpha, beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verosimilitud: 9998638.115005765\n",
      "Verosimilitud: 13.628329134145588\n",
      "Verosimilitud: 31.104994377176354\n",
      "Verosimilitud: 56.159227338884875\n",
      "Verosimilitud: 52.320428014990966\n",
      "Verosimilitud: 30.32196352383835\n",
      "Verosimilitud: 16.66017736551339\n",
      "Verosimilitud: 8.502573441662662\n",
      "Verosimilitud: 5.01178724309375\n",
      "Verosimilitud: 3.076003630393643\n",
      "Verosimilitud: 2.1168256440464575\n",
      "Verosimilitud: 1.845699420199253\n",
      "Verosimilitud: 1.8244322915011253\n",
      "Verosimilitud: 1.8893136480705834\n",
      "Verosimilitud: 2.3496160699342\n",
      "Verosimilitud: 2.5289299210394347\n",
      "Verosimilitud: 2.622556209738832\n",
      "Verosimilitud: 2.2653312756456216\n",
      "Verosimilitud: 0.7808425710099982\n",
      "Verosimilitud: 0.3021274681407249\n",
      "Verosimilitud: 0.12589109695250045\n"
     ]
    }
   ],
   "source": [
    "w, alpha, beta = training_LFCmodel(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[:,'b'] = 0.0\n",
    "predtest = sigmoid(np.dot(X_test,w))\n",
    "y_pred = [True if item >= 0.5 else False for item in predtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Precision:\n",
      "0.9298245614035088\n",
      "\n",
      "\n",
      "General Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.94      0.94      0.94       108\n",
      "          no       0.90      0.90      0.90        63\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.92      0.92       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      "     0   1\n",
      "0  102   6\n",
      "1    6  57\n"
     ]
    }
   ],
   "source": [
    "eval_model(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
