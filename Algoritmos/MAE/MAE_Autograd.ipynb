{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFwgcFgqYSMM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from autograd import grad\n",
    "import autograd.numpy as np\n",
    "import numpy as np1\n",
    "import numpy.matlib\n",
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n",
    "from numpy.matlib import repmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2_7Xq97YSMP"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Python/')\n",
    "from Preprocessing import standardize\n",
    "from Evaluation import split_train_test_ma, train_model, test_model\n",
    "from Databases import get_databases_path, get_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJePEly1YSMS"
   },
   "outputs": [],
   "source": [
    "databases_path = '../../Databases/Sinteticas'\n",
    "paths = get_databases_path(databases_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PI2Nm-tuYSMW"
   },
   "outputs": [],
   "source": [
    "# Obtain the attributes and labels\n",
    "attr_df = get_database(paths[1], 'database_attr.csv')\n",
    "labels_df = get_database(paths[1], 'database_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RXOiomqMYSMY"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the attributes\n",
    "standardized_attr_df = standardize(attr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izYZHfmvYSMb"
   },
   "outputs": [],
   "source": [
    "# Split in Training and Test Sets\n",
    "X_train, X_test, y_train, y_test = split_train_test_ma(standardized_attr_df, labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xa9pBV6DYSMd"
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1./(1 + np.exp(-a))\n",
    "\n",
    "def make_cost_function(X, Y, mui):\n",
    "    def cost_function(w):\n",
    "        R = Y.shape[1]\n",
    "        N = Y.shape[0]\n",
    "        sizew1 = X.shape[1]\n",
    "        sizeW = sizew1 + sizew1*R\n",
    "\n",
    "        W1 = w[0,0:sizew1].reshape(sizew1,1)\n",
    "        W2 = w[0,sizew1:sizeW].reshape(sizew1,R)\n",
    "\n",
    "        pi = sigmoid(np.dot(X, W1))        \n",
    "        aux = sigmoid(np.dot(X,W2))\n",
    "        \n",
    "        ai = np.multiply(np.power((1-aux),np.absolute(Y-1)),np.power(aux, (1-np.absolute(Y-1))))\n",
    "        ai = np.array(np.prod(ai, axis=1)).reshape(ai.shape[0],1) \n",
    "\n",
    "        bi = np.multiply(np.power((1-aux),np.absolute(Y)),np.power(aux, (1-np.absolute(Y))))\n",
    "        bi = np.array(np.prod(bi, axis=1)).reshape(bi.shape[0],1) \n",
    "\n",
    "        aux_0 = 1-mui \n",
    "        aux_1 = 1-pi \n",
    "\n",
    "        aux_a = np.multiply(mui, np.log(np.multiply(pi, ai))) \n",
    "        aux_b = np.multiply(aux_0, np.log(np.multiply(aux_1, bi))) \n",
    "\n",
    "        return -(aux_a + aux_b).sum()\n",
    "    return cost_function\n",
    "         \n",
    "def optimizer(X, Y, w_0, mui):\n",
    "    derivate = grad(make_cost_function(X, Y, mui)) \n",
    "    params = w_0\n",
    "    epsilon = 0.001\n",
    "    normGrad = 100\n",
    "    i=0\n",
    "    while normGrad > 0.1 and i<300:\n",
    "        gr = derivate(params)\n",
    "        params = params - epsilon * gr\n",
    "        normGrad = LA.norm(gr)\n",
    "        i+=1\n",
    "    return params, normGrad\n",
    "    \n",
    "def train_mae(X, Y):\n",
    "    X.loc[:,'b'] = np.zeros((X.shape[0],1))\n",
    "    X = X.values\n",
    "    Y = Y.values\n",
    "    R = Y.shape[1] # Number of annotators.\n",
    "    D = X.shape[1] # Input space dimension\n",
    "    N = X.shape[0] # Number of samples.\n",
    "    \n",
    "    sizew1 = D\n",
    "    sizew2 = D*R;\n",
    "    sizeW = sizew1 + sizew2\n",
    "    \n",
    "    w = np.random.randn(1, sizeW)\n",
    "    mui = np.array(Y.mean(axis=1)).reshape(Y.shape[0],1)\n",
    "    \n",
    "    w = repmat(np.dot(inv(np.dot(X.T,X) + 1e-20*np.eye(D)), np.dot(X.T,mui)),1,R+1)\n",
    "    w = w.flatten().reshape(1, sizeW)\n",
    "    \n",
    "    w_0 = w\n",
    "    loglik1 = 10000000\n",
    "    difloglik = 100\n",
    "    difloglik1 = -1\n",
    "    i = 0\n",
    "    \n",
    "    while abs(difloglik) > 0.2 and i<100:\n",
    "        # M-step     \n",
    "        w, Ngr = optimizer(X, Y, w_0, mui)\n",
    "        W1 = w[0,0:sizew1].reshape(sizew1,1)\n",
    "        W2 = w[0,sizew1:sizeW].reshape(D,R)\n",
    "\n",
    "        #E-step\n",
    "        pi = sigmoid(np.dot(X, W1))\n",
    "        aux = sigmoid(np.dot(X,W2))\n",
    "\n",
    "        ai = np.multiply(np.power((1-aux),np.absolute(Y-1)),np.power(aux, (1-np.absolute(Y-1))))\n",
    "        ai = np.array(np.prod(ai, axis=1)).reshape(ai.shape[0],1) \n",
    "\n",
    "        bi = np.multiply(np.power((1-aux),np.absolute(Y)),np.power(aux, (1-np.absolute(Y))))\n",
    "        bi = np.array(np.prod(bi, axis=1)).reshape(bi.shape[0],1) \n",
    "\n",
    "        nummui = np.multiply(ai, pi)\n",
    "        denmui = (np.multiply(ai, pi) + np.multiply(bi, (1-pi))) \n",
    "        mui =  np.divide(nummui, denmui)\n",
    "\n",
    "        aux_0 = 1-mui \n",
    "        aux_1 = 1-pi \n",
    "        aux_a = np.multiply(mui, np.log(np.multiply(pi, ai))) \n",
    "        aux_b = np.multiply(aux_0, np.log(np.multiply(aux_1, bi))) \n",
    "\n",
    "        loglik2 = -(aux_a + aux_b).sum()\n",
    "        difloglik = (loglik2 - loglik1);\n",
    "        loglik1 = loglik2\n",
    "        print('Verosimilitud:', abs(difloglik))\n",
    "        \n",
    "        w_0 = w\n",
    "        i+=1\n",
    "    return w[0,0:sizew1].reshape(sizew1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yeGgcDV1YSMi",
    "outputId": "5e10a877-4926-443a-c36f-4546c532f98c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verosimilitud: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:635: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/tracer.py:48: RuntimeWarning: divide by zero encountered in log\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/tracer.py:48: RuntimeWarning: invalid value encountered in multiply\n",
      "  return f_raw(*args, **kwargs)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:76: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:76: RuntimeWarning: invalid value encountered in true_divide\n",
      "  defvjp(anp.log,    lambda ans, x : lambda g: g / x)\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:34: RuntimeWarning: invalid value encountered in multiply\n",
      "  defvjp(anp.multiply,    lambda ans, x, y : unbroadcast_f(x, lambda g: y * g),\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:35: RuntimeWarning: invalid value encountered in multiply\n",
      "  lambda ans, x, y : unbroadcast_f(y, lambda g: x * g))\n",
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/autograd/numpy/numpy_vjps.py:243: RuntimeWarning: invalid value encountered in multiply\n",
      "  g_repeated, _ = repeat_to_match_shape(g * ans, shape, dtype, axis, keepdims)\n"
     ]
    }
   ],
   "source": [
    "W1 = train_mae(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[:,'b'] = 0.0\n",
    "pred = sigmoid(np.dot(X_test, W1))\n",
    "y_pred = [True if item >= 0.5 else False for item in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DoG9lXUGjUWo",
    "outputId": "8cdc4cea-1da3-44c8-e21f-c793388871e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Precision:\n",
      "0.3225806451612903\n",
      "\n",
      "\n",
      "General Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         yes       0.32      1.00      0.49        30\n",
      "          no       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.32        93\n",
      "   macro avg       0.16      0.50      0.24        93\n",
      "weighted avg       0.10      0.32      0.16        93\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      "    0  1\n",
      "0  30  0\n",
      "1  63  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codigoriginal/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "print(\"Global Precision:\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"General Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['yes','no']))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "matriz_confusion = confusion_matrix(y_test, y_pred)\n",
    "table = pd.DataFrame(matriz_confusion)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MAE-Autograd.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
